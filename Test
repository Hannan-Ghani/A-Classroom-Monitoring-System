from pyspark.conf import SparkConf
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, regexp_replace, explode

# Set up Spark configuration
conf = SparkConf().setAll([
    ('spark.executor.memory', '130g'),
    ('spark.executor.cores', '1'),
    ('spark.executor.instances', '5'),
    ('spark.cores.max', '1'),
    ('spark.driver.memory', '160g')
])

# Initialize Spark session
spark = SparkSession.builder.config(conf=conf).getOrCreate()

# Read the customer data from core
a_cus = spark.read.parquet('s3://136731789529-fis-raw-data/customer/20240129/raw/parquet/*.parquet') \
    .filter("NUM_OF_ACCOUNT >= 0 and (SOURCE_COUNTRY <> 'ZA' or SOURCE_COUNTRY is NULL) and customer_key is not null") \
    .withColumn('customerUniqueId', regexp_replace(col('customer_key'), '[^\\w]', ''))

a_cus.createOrReplaceTempView('a_cus')

# Read the product data from two sources
Prod_fortent = spark.read.parquet('s3://136731789529-fis-raw-data/uk1/product/20230719/raw/parquet/')
Prod_fortent.createOrReplaceTempView('Prod_fortent')

Prod_core = spark.read.parquet('s3://136731789529-fis-raw-data/product/20240129/raw/parquet/*.parquet')
Prod_core.createOrReplaceTempView('Prod_core')

# Union of product data
prodJoin = spark.sql("SELECT * FROM Prod_core UNION SELECT * FROM Prod_fortent")
prodJoin.createOrReplaceTempView('prodJoin')

# Filter joined product data
a_prod = prodJoin.filter(
    (col('account_key').isNotNull() | col('customer_key').isNotNull()) &
    (~col('customer_role').isin("CML - COMP PARENT", "PRIMARY")) &
    (col('low_account_type').isin(
        "UKCMLPVHI", "UKCMLPV100", "UKCMLPV5K", "UKCMLPV500", "UKCMLPV10K",
        "UKCMLPV1K", "UKCMLPVUNK", "UKCMLPBHI", "UKCMLPB100", "UKCMLPB5K",
        "UKCMLPB500", "UKCMLPB1K", "UKCM"
    ))
).withColumn('customerUniqueId', regexp_replace(col('customer_key'), '[^\\w]', ''))

a_prod.createOrReplaceTempView('a_prod')

# Join customer and product data
prod_qtx = spark.sql("""
    SELECT * 
    FROM a_cus 
    INNER JOIN a_prod ON a_cus.customerUniqueId = a_prod.customerUniqueId
""").dropDuplicates()

prod_qtx.createOrReplaceTempView('prod_qtx')

# Output the results or save to S3
output_path = "s3://your-output-bucket/path/to/save/results"
prod_qtx.write.mode("overwrite").parquet(output_path)

print("ETL job completed successfully.")