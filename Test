from pyspark.sql import SparkSession
from pyspark.sql.functions import col, udf
import boto3

# Initialize SparkSession
spark = SparkSession.builder.appName("CleanseCaseClass").getOrCreate()

# ==============================
# Configuration Parameters
# ==============================

# Define S3 paths for configuration and output files
s3ConfigPath = "s3://your-bucket/paths_config.txt"
s3ColumnsConfigPath = "s3://your-bucket/columns_config.txt"
outputSummaryPath = "s3://your-bucket/output_summary.txt"

# ==============================
# Load Configurations
# ==============================

# Helper function to read configurations from S3
def read_config_from_s3(s3_path):
    s3 = boto3.client('s3')
    bucket, key = s3_path.replace("s3://", "").split("/", 1)
    obj = s3.get_object(Bucket=bucket, Key=key)
    config = {}
    for line in obj['Body'].read().decode("utf-8").splitlines():
        key, value = line.strip().split('=')
        config[key.strip()] = value.strip()
    return config

configMap = read_config_from_s3(s3ConfigPath)
inputSourcePath = configMap["inputSourcePath"]
inputTargetPath = configMap["inputTargetPath"]
outputBasePath = configMap["outputBasePath"]

columnConfig = read_config_from_s3(s3ColumnsConfigPath)

# ==============================
# Load Data from S3 Paths
# ==============================
transactionSource = spark.read.parquet(inputSourcePath)
caseClass = spark.read.parquet(inputTargetPath)

# Initialize validation summary string
validationSummary = "Validation Results Summary:\n"

# ==============================
# Country Code Mapping UDF
# ==============================
countryCodeMapping = {
    "US": "USA", "CA": "CAN", "MX": "MEX", "GB": "GBR", "FR": "FRA",
    "DE": "DEU", "IN": "IND", "CN": "CHN", "JP": "JPN", "AU": "AUS"
}

def map_country_code(code):
    return countryCodeMapping.get(code, code)

# Register the UDF in Spark
mapCountryCodeUDF = udf(map_country_code)

# ==============================
# Null Value Validation
# ==============================
nullColumns = columnConfig.get("null_validation.columns", "").split(',')
existingNullColumns = [col for col in nullColumns if col in caseClass.columns]

nullValidationCount = caseClass.filter(lambda row: any(row[col] is None for col in existingNullColumns)).count()
validationSummary += f"Null Validation: {nullValidationCount} found\n"

# ==============================
# Direct Column Validation
# ==============================
sourceDirectColumns = columnConfig.get("direct_column_validation.columns_source", "").split(',')
targetDirectColumns = columnConfig.get("direct_column_validation.columns_target", "").split(',')

directSourceData = transactionSource.select([col(c) for c in sourceDirectColumns])
directTargetData = caseClass.select([col(c) for c in targetDirectColumns])

# Source-to-target and target-to-source differences
directSourceToTargetDiff = directSourceData.exceptAll(directTargetData)
directTargetToSourceDiff = directTargetData.exceptAll(directSourceData)

# Collect counts and IDs without reassigning to avoid overwrites
directSourceToTargetCount = directSourceToTargetDiff.count()
directTargetToSourceCount = directTargetToSourceDiff.count()
directSourceToTargetIds = ", ".join([row["TRANSACTION_ID"] for row in directSourceToTargetDiff.select("TRANSACTION_ID").collect()])
directTargetToSourceIds = ", ".join([row["transactionId"] for row in directTargetToSourceDiff.select("transactionId").collect()])

validationSummary += f"Direct Column Validation: {directSourceToTargetCount + directTargetToSourceCount} found\n"
validationSummary += f"Source to Target Transaction IDs: {directSourceToTargetIds}\n"
validationSummary += f"Target to Source Transaction IDs: {directTargetToSourceIds}\n"

# ==============================
# Country ISO3 Validation with Mapping
# ==============================
sourceCountryColumn = columnConfig["transaction_country_iso3_validation.source_column"]
targetCountryColumn = columnConfig["transaction_country_iso3_validation.target_column"]

# Apply country code mapping to source data
sourceCountryData = transactionSource.withColumn("isoCountryCodeMapped", mapCountryCodeUDF(col(sourceCountryColumn)))
targetCountryData = caseClass.select(col("transactionId"), col(targetCountryColumn).alias("isoCountryCode"))

countrySourceToTargetDiff = sourceCountryData.select("TRANSACTION_ID", "isoCountryCodeMapped").exceptAll(targetCountryData)
countryTargetToSourceDiff = targetCountryData.exceptAll(sourceCountryData.select("TRANSACTION_ID", "isoCountryCodeMapped"))

# Count and collect IDs for differences
countrySourceToTargetCount = countrySourceToTargetDiff.count()
countryTargetToSourceCount = countryTargetToSourceDiff.count()
countrySourceToTargetIds = ", ".join([row["TRANSACTION_ID"] for row in countrySourceToTargetDiff.select("TRANSACTION_ID").collect()])
countryTargetToSourceIds = ", ".join([row["transactionId"] for row in countryTargetToSourceDiff.select("transactionId").collect()])

validationSummary += f"Country ISO3 Validation: {countrySourceToTargetCount + countryTargetToSourceCount} found\n"
validationSummary += f"Source to Target Transaction IDs: {countrySourceToTargetIds}\n"
validationSummary += f"Target to Source Transaction IDs: {countryTargetToSourceIds}\n"

# ==============================
# Write Validation Summary to S3
# ==============================

# Helper function to write summary to S3
def write_summary_to_s3(summary, s3_path):
    s3 = boto3.resource('s3')
    bucket, key = s3_path.replace("s3://", "").split("/", 1)
    s3.Object(bucket, key).put(Body=summary)

write_summary_to_s3(validationSummary, outputSummaryPath)

# Stop Spark session
spark.stop()