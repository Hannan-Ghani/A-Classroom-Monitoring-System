import com.amazonaws.services.glue.GlueContext
import com.amazonaws.services.glue.util.Job
import org.apache.spark.SparkContext
import org.apache.spark.sql.{DataFrame, SparkSession, Row}
import org.apache.spark.sql.functions._
import org.apache.log4j.Logger
import com.amazonaws.services.glue.util.GlueArgParser

object DynamicCaseClass {

  // Initialize logger globally
  val logger: Logger = Logger.getLogger(this.getClass.getName)

  def main(sysArgs: Array[String]): Unit = {
    // Initialize SparkSession
    val spark: SparkSession = SparkSession.builder().getOrCreate()

    val glueContext: GlueContext = new GlueContext(spark.sparkContext)

    // Use spark.implicits instead of sparkSession.implicits
    import spark.implicits._

    // Get Glue job parameters for config paths
    val args = GlueArgParser.getResolvedOptions(sysArgs, Seq("s3PathConfig", "s3ValidationConfig").toArray)
    val s3PathConfig = args("s3PathConfig")
    val s3ValidationConfig = args("s3ValidationConfig")

    // 1. Read and parse the Path Config file (S3)
    val pathConfig = readPathConfig(spark.read.textFile(s3PathConfig).collect())

    // 2. Read and parse the Validation Config file (S3)
    val validationConfig = parseValidationConfig(spark.read.textFile(s3ValidationConfig).collect())

    // Extract paths from the pathConfig map
    val inputSourcePath = pathConfig.getOrElse("inputSourcePath", "")
    val inputTargetPath = pathConfig.getOrElse("inputTargetPath", "")
    val outputBasePath = pathConfig.getOrElse("outputBasePath", "")

    // Load source and target data
    val transactionSource: DataFrame = spark.read.parquet(inputSourcePath)
    val caseClass: DataFrame = spark.read.parquet(inputTargetPath)

    // =======================
    // Combine Results from all Validations
    // =======================

    // Initialize an empty DataFrame for combining all validation results
    var combinedResults: DataFrame = transactionSource.select(col("TRANSACTION_ID"))

    // Null Validation
    if (validationConfig.contains("null_validation")) {
      val nullColumns = validationConfig("null_validation")("columns")
      val nullValidationResult = applyNullValidation(nullColumns, caseClass)(spark)
      combinedResults = combinedResults.join(nullValidationResult, Seq("TRANSACTION_ID"), "outer")
    }

    // Direct Column Validation
    if (validationConfig.contains("direct_column_validation")) {
      val sourceCols = validationConfig("direct_column_validation")("columns_source")
      val targetCols = validationConfig("direct_column_validation")("columns_target")
      val directValidationResult = applyDirectColumnValidation(sourceCols, targetCols, transactionSource, caseClass)(spark)
      combinedResults = combinedResults.join(directValidationResult, Seq("TRANSACTION_ID"), "outer")
    }

    // Narrative Validation
    if (validationConfig.contains("narrative_validation")) {
      val sourceNarrativeCol = validationConfig("narrative_validation")("source_column")
      val targetNarrativeCol = validationConfig("narrative_validation")("target_column")
      val narrativeValidationResult = applyNarrativeValidation(sourceNarrativeCol, targetNarrativeCol, transactionSource, caseClass)(spark)
      combinedResults = combinedResults.join(narrativeValidationResult, Seq("TRANSACTION_ID"), "outer")
    }

    // Amount Local Validation
    if (validationConfig.contains("amount_local_validation")) {
      val sourceAmountCol = validationConfig("amount_local_validation")("source_column")
      val targetAmountCol = validationConfig("amount_local_validation")("target_column")
      val amountLocalValidationResult = applyAmountLocalValidation(sourceAmountCol, targetAmountCol, transactionSource, caseClass)(spark)
      combinedResults = combinedResults.join(amountLocalValidationResult, Seq("TRANSACTION_ID"), "outer")
    }

    // Transaction Country ISO3 Validation
    if (validationConfig.contains("transaction_country_iso3_validation")) {
      val sourceCountryCol = validationConfig("transaction_country_iso3_validation")("source_column")
      val targetCountryCol = validationConfig("transaction_country_iso3_validation")("target_column")
      val countryIsoValidationResult = applyTransactionCountryISO3Validation(sourceCountryCol, targetCountryCol, transactionSource, caseClass)(spark)
      combinedResults = combinedResults.join(countryIsoValidationResult, Seq("TRANSACTION_ID"), "outer")
    }

    // Write the combined result to S3 as a single Parquet file
    val combinedOutputPath = s"${outputBasePath}/combined_validation_output/"
    combinedResults.write.mode("overwrite").parquet(combinedOutputPath)

    // Commit the Glue job to mark it as completed
    Job.commit()
  }

  // =======================
  // Helper Functions for Config Parsing
  // =======================

  // Function to read and parse path configuration
  def readPathConfig(config: Array[String]): Map[String, String] = {
    config.filterNot(line => line.trim.isEmpty || line.trim.startsWith("#")).flatMap { line =>
      line.split("=").map(_.trim) match {
        case Array(key, value) if key.nonEmpty && value.nonEmpty =>
          Some(key -> value)
        case _ =>
          logger.warn(s"Invalid line in path config: $line")
          None
      }
    }.toMap
  }

  // Function to read and parse validation configuration
  def parseValidationConfig(config: Array[String]): Map[String, Map[String, String]] = {
    var currentSection: String = ""
    var validationConfig: Map[String, Map[String, String]] = Map()

    config.filterNot(line => line.trim.isEmpty || line.trim.startsWith("#")).foreach { line =>
      if (line.startsWith("[") && line.endsWith("]")) {
        currentSection = line.substring(1, line.length - 1).trim
        validationConfig += (currentSection -> Map())
      } else {
        val keyValue = line.split("=").map(_.trim)
        if (keyValue.length == 2 && currentSection.nonEmpty) {
          val currentValues = validationConfig(currentSection)
          validationConfig += (currentSection -> (currentValues + (keyValue(0) -> keyValue(1))))
        } else {
          logger.warn(s"Invalid line in validation config: $line")
        }
      }
    }

    validationConfig
  }

  // =======================
  // Validation Functions
  // =======================

  // Null Value Validation
  def applyNullValidation(columns: String, caseClass: DataFrame)(implicit spark: SparkSession): DataFrame = {
    val nullColumns = columns.split(",").map(colName => col(colName).alias(s"null_$colName")).toSeq
    caseClass.select(col("TRANSACTION_ID") +: nullColumns: _*).distinct()
  }

  // Direct Column Validation
  def applyDirectColumnValidation(sourceCols: String, targetCols: String, transactionSource: DataFrame, caseClass: DataFrame)(implicit spark: SparkSession): DataFrame = {
    val sourceColumns = sourceCols.split(",").map(colName => col(colName).alias(s"direct_source_$colName")).toSeq
    val targetColumns = targetCols.split(",").map(colName => col(colName).alias(s"direct_target_$colName")).toSeq

    val sourceDirectData = transactionSource.select(col("TRANSACTION_ID") +: sourceColumns: _*)
    val targetDirectData = caseClass.select(col("transactionId").alias("TRANSACTION_ID") +: targetColumns: _*)

    sourceDirectData.join(targetDirectData, Seq("TRANSACTION_ID"), "outer")
  }

  // Narrative Validation
  def applyNarrativeValidation(sourceNarrativeCol: String, targetNarrativeCol: String, transactionSource: DataFrame, caseClass: DataFrame)(implicit spark: SparkSession): DataFrame = {
    val sourceNarrativeData = transactionSource.select(col("TRANSACTION_ID"), col(sourceNarrativeCol).alias(s"narrative_source_$sourceNarrativeCol"))
    val targetNarrativeData = caseClass.select(col("transactionId").alias("TRANSACTION_ID"), col(targetNarrativeCol).alias(s"narrative_target_$targetNarrativeCol"))

    sourceNarrativeData.join(targetNarrativeData, Seq("TRANSACTION_ID"), "outer")
  }

  // Amount Local Validation
  def applyAmountLocalValidation(sourceAmountCol: String, targetAmountCol: String, transactionSource: DataFrame, caseClass: DataFrame)(implicit spark: SparkSession): DataFrame = {
    val sourceAmountData = transactionSource.select(col("TRANSACTION_ID"), col(sourceAmountCol).alias(s"amount_source_$sourceAmountCol"))
    val targetAmountData = caseClass.select(col("transactionId").alias("TRANSACTION_ID"), col(targetAmountCol).alias(s"amount_target_$targetAmountCol"))

    sourceAmountData.join(targetAmountData, Seq("TRANSACTION_ID"), "outer")
  }

  // Transaction Country ISO3 Validation
  def applyTransactionCountryISO3Validation(sourceCountryCol: String, targetCountryCol: String, transactionSource: DataFrame, caseClass: DataFrame)(implicit spark: SparkSession): DataFrame = {
    val mappingUDF = udf((input: String) => Map("AD" -> "AND", "AE" -> "ARE", "AF" -> "AFG", "AG" -> "ATG", "AI" -> "AIA").getOrElse(input, input))

    val sourceTransactionCountry = transactionSource.withColumn("transactionCountryIso3Mapped", mappingUDF(col(sourceCountryCol)))
    val targetTransactionCountry = caseClass.select(col(targetCountryCol).alias("transactionCountryIso3Mapped"))

    sourceTransactionCountry.join(targetTransactionCountry, Seq("TRANSACTION_ID"), "outer")
  }

  // =======================
  // Helper Functions
  // =======================

  // Helper function to filter out missing columns in source and target
  def filterExistingColumnPairs(sourceColumns: Seq[String], targetColumns: Seq[String], transactionSource: DataFrame, caseClass: DataFrame): (Seq[String], Seq[String]) = {
    val existingSourceColumns = filterExistingColumns(transactionSource, sourceColumns)
    val existingTargetColumns = filterExistingColumns(caseClass, targetColumns)

    sourceColumns.zip(targetColumns).filter { case (sourceCol, targetCol) =>
      existingSourceColumns.contains(sourceCol) && existingTargetColumns.contains(targetCol)
    }.unzip
  }

  // Helper function to filter out missing columns in general
  def filterExistingColumns(df: DataFrame, columns: Seq[String]): Seq[String] = {
    val existingColumns = df.columns.toSet
    columns.filter(existingColumns.contains)
  }
}