def applyNullValidation(columns: String, caseClass: DataFrame)(implicit spark: SparkSession): DataFrame = {
    import spark.implicits._

    // Split the columns string and filter to only include columns that exist in caseClass
    val nullColumns = columns.split(",").map(_.trim).toSeq
    val filteredColumns = nullColumns.filter(colName => caseClass.columns.contains(colName))

    // If no valid columns are found, return an empty DataFrame
    if (filteredColumns.isEmpty) {
        logger.warn("No valid columns found for null validation.")
        return spark.createDataFrame(spark.sparkContext.emptyRDD[Row], caseClass.schema)
    }

    // Filter rows where all specified columns are null
    val nullFilteredData = caseClass.filter(filteredColumns.map(colName => col(colName).isNull).reduce(_ && _))

    // Add a validation type column for identification and return the result
    nullFilteredData.withColumn("ValidationType", lit("Null Validation"))
}



// Null Validation
if (validationConfig.contains("null_validation")) {
    val nullColumns = validationConfig("null_validation")("columns")
    val nullValidationResult = applyNullValidation(nullColumns, caseClass)(spark)
    combinedResults = mergeWithCombinedResults(combinedResults, nullValidationResult)
}