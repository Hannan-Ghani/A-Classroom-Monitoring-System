import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
import com.amazonaws.services.glue.util.GlueArgParser

object TransactionProcessing {

  def main(sysArgs: Array[String]): Unit = {
    // Initialize Spark Session
    val spark = SparkSession.builder.appName("TransactionProcessing").getOrCreate()

    // Import implicits for using $"column_name" syntax
    import spark.implicits._

    // Retrieve job parameters from Glue job configuration
    val args = GlueArgParser.getResolvedOptions(sysArgs, Seq(
      "SOURCE_PATH",           // S3 path for source data
      "TARGET_PATH",           // S3 path for target output
      "OUTPUT_PATH"            // S3 path for saving difference results
    ).toArray)

    // Extract parameter values
    val sourcePath = args("SOURCE_PATH")             // Path to source data
    val targetPath = args("TARGET_PATH")             // Path to target data
    val outputPath = args("OUTPUT_PATH")             // Path to save differences

    // Load source and target DataFrames from S3
    val source = spark.read.parquet(sourcePath)
    val target = spark.read.parquet(targetPath)

    // Find differences: Rows in source but not in target
    val differences = source.exceptAll(target)

    // Optionally, find rows in target but not in source (reverse comparison)
    val reverseDifferences = target.exceptAll(source)

    // Save the differences to the specified S3 path as a Parquet file
    differences.write.mode("overwrite").parquet(s"$outputPath/source_not_in_target")

    // Save reverse differences if needed
    reverseDifferences.write.mode("overwrite").parquet(s"$outputPath/target_not_in_source")

    // Log the path where the data is saved
    println(s"Differences (source not in target) have been saved to: $outputPath/source_not_in_target")
    println(s"Differences (target not in source) have been saved to: $outputPath/target_not_in_source")
  }
}