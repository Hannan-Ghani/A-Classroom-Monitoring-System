import sys
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from awsglue.utils import getResolvedOptions
from pyspark.sql.functions import col, regexp_replace, when

# Read job parameters
args = getResolvedOptions(sys.argv, ['JOB_NAME', 'CUSTOMER_PATH', 'PRODUCT_FORTENT_PATH', 'PRODUCT_CORE_PATH'])
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

# Read customer data from the S3 path provided in the parameter
a_cus = spark.read.parquet(args['CUSTOMER_PATH'])\
    .filter("NUM_OF_ACCOUNT >= 0 and (SOURCE_COUNTRY <> 'ZA' Or SOURCE_COUNTRY IS NULL) and customer_key is not null and customer_key not in('', '***', 'TTMAMC-**', 'TMEMA-**', 'TMUK1-**', 'MUK2-**', 'Not Available')")\
    .withColumn('customerUniqueId', regexp_replace(col('customer_key'), '^-', ''))
a_cus.createOrReplaceTempView('a_cus')
a_cus.cache()

# Read product fortent data from the S3 path provided in the parameter
Prod_fortent = spark.read.parquet(args['PRODUCT_FORTENT_PATH'])
Prod_fortent.createOrReplaceTempView('Prod_fortent')
Prod_fortent.cache()

# Read product core data from the S3 path provided in the parameter
Prod_core = spark.read.parquet(args['PRODUCT_CORE_PATH'])
Prod_core.createOrReplaceTempView('Prod_core')
Prod_core.cache()

# Perform the UNION operation between Prod_core and Prod_fortent
prodJoin = spark.sql("""
    SELECT * FROM Prod_core
    UNION
    SELECT * FROM Prod_fortent
""")
prodJoin.createOrReplaceTempView('prodJoin')

# Apply the filter on the records
a_prod = prodJoin.filter(
    (col('account_key').isNotNull() | col('customer_key').isNotNull()) & 
    (when(
        (col('screening_system') == "TMUK2") &
        ((~col('customer_role').isin("CML - COMP PARENT", "PRIMARY")) | 
         (col('low_account_type').isin("CML - COMP PARENT", "PRIMARY"))) | 
        (col('low_account_type').isin(
            "UKCMPVHI", "UKCMLPV100", "UKCMLPV5K", "UKCMLPV500", "UKCMLPV10K", 
            "UKCMLPV1K", "UKCMPVUNK", "UKCMLPBHI", "UKCMLPB100", "UKCMLPB5K", 
            "UKCMLPB500", "UKCMLPB1K", "UKCMLPBUNK"))
    , True).otherwise(False))
)

a_prod.createOrReplaceTempView('a_prod')
a_prod.cache()

# Perform an inner join between a_cus and a_prod on customerUniqueId
prod_qtx = a_cus.join(a_prod, a_cus.customerUniqueId == a_prod.customerUniqueId, how='inner')\
    .select(a_prod['*'])\
    .dropDuplicates()

# Create or replace a temporary view and cache it
prod_qtx.createOrReplaceTempView('prod_qtx')
prod_qtx.cache()

# Query: Count distinct customerUniqueId
custJoin = spark.sql("""
    SELECT count(DISTINCT(customerUniqueId)) FROM prod_qtx
""")
custJoin.show(10, False)

# Query: Count total customerUniqueId
custJoin = spark.sql("""
    SELECT count(customerUniqueId) FROM prod_qtx
""")
custJoin.show(10, False)

# Commit the Glue job
job.commit()