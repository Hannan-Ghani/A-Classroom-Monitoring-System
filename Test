import sys
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, expr
from awsglue.utils import getResolvedOptions
from awsglue.context import GlueContext
from awsglue.job import Job

# Initialize Glue job
args = getResolvedOptions(sys.argv, ['JOB_NAME'])
spark = SparkSession.builder.appName('GlueJob').getOrCreate()
glueContext = GlueContext(spark.sparkContext)
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

# Read Raw file (Payment Raw Cleanse Case class)
payment_create = spark.read.parquet("s3://136731789529-fis-interim-data/payment/202202-202301-uk-uae-Full/DocumentDataModel/CleansedDocumentDataModel.parquet/")
payment_create.createOrReplaceTempView("payment_create")

# Read target file (Payment Aggregate Create Case class)
pagg_create = spark.read.parquet("s3://136731789529-fis-interim-data/aggregatedPayments/2023-96-14_11-49-35-565/DocumentDataModel/DocumentDataModel.parquet/*")
pagg_create.createOrReplaceTempView("pagg_create")

# Check count
raw_count = spark.sql("""
    SELECT count(distinct ukAggregationId) as count, 'Payment Raw' as source FROM payment_create
    WHERE sourcesystem IN ('FPSBI', 'FPSBUK')
    AND originator.accountNumber <> beneficiary.accountNumber
    UNION ALL
    SELECT count(*) as count, 'Payment Aggregate' as source FROM pagg_create
""")
raw_count.write.mode("overwrite").csv("s3://your-output-bucket/path/raw_count.csv")

# Fetch account details from Payment Raw
payment_data_val_aAccount = spark.sql("""
    SELECT distinct PO.ukAggregationId, originator.accountNumber as aAccountUniqueId,
           originator.id, originator.accountNumber, originator.sortCode, originator.iban, 
           originator.cleansedAccountNumber, originator.cleansedSortCode,
           COALESCE(originator.countryCode, originator.parsedAddress.countryCode) as aBankCountryIso3,
           originator.parsedAddress.addressDisplay, originator.Name
    FROM payment_create PO 
    WHERE sourcesystem IN ('FPSBI', 'FPSBUK')
    AND originator.accountNumber <> beneficiary.accountNumber
""")
payment_data_val_aAccount.createOrReplaceTempView("payment_data_val_aAccount")

# Fetch account details from Payment Aggregate Document Data Model
pagg_data_val_aAccount = spark.sql("""
    SELECT aggregatedTransactionId, aAccount.accountUniqueId as aAccountUniqueId,
           aAccount.accountId as aAccountId, aAccount.accountNumber, aAccount.accountSortCode as aSortCode,
           aAccount.accountIban as aIban, aAccount.cleansedAccountNumber as AccountNumberCleansed, 
           aAccount.cleansedSortCode as aSortCodeCleansed, aAccount.accountCountry as aBankCountry,
           aAccount.accountCountryIso3 as aBankCountryIso3, aAccount.Address as Address, 
           aAccount.party.partyName as aName
    FROM pagg_create
""")
pagg_data_val_aAccount.createOrReplaceTempView("pagg_data_val_aAccount")

# Compare Account Data
pagg_data_val_aAccount.exceptAll(payment_data_val_aAccount).show(10, False)
payment_data_val_aAccount.exceptAll(pagg_data_val_aAccount).show(10, False)

# Fetch bAccount details from Payment Raw
payment_data_val_bAccount = spark.sql("""
    SELECT distinct PO.ukAggregationId, beneficiary.accountNumber as bAccountUniqueId,
           beneficiary.id, beneficiary.accountNumber, beneficiary.sortCode, 
           beneficiary.iban, beneficiary.cleansedAccountNumber, beneficiary.cleansedSortCode,
           COALESCE(beneficiary.countryCode, beneficiary.parsedAddress.countryCode) as bBankCountryIso3,
           beneficiary.parsedAddress.addressDisplay, beneficiary.Name
    FROM payment_create PO 
    WHERE sourcesystem IN ('FPSBI', 'FPSBUK')
    AND originator.accountNumber <> beneficiary.accountNumber
""")
payment_data_val_bAccount.createOrReplaceTempView("payment_data_val_bAccount")

# Fetch bAccount details from Payment Aggregate Document Data Model
pagg_data_val_bAccount = spark.sql("""
    SELECT aggregatedTransactionId, bAccount.accountUniqueId as bAccountUniqueId,
           bAccount.accountId as bAccountId, bAccount.accountNumber as bAccountNumber,
           bAccount.accountSortCode as bSortCode, bAccount.accountIban as bIban,
           bAccount.cleansedAccountNumber as bAccountNumberCleansed, 
           bAccount.cleansedSortCode as bSortCodeCleansed, bAccount.accountCountry as bBankCountry,
           bAccount.accountCountryIso3 as bBankCountryIso3, bAccount.Address as bAddress, 
           bAccount.party.partyName as bName
    FROM pagg_create
""")
pagg_data_val_bAccount.createOrReplaceTempView("pagg_data_val_bAccount")

# Compare bAccount Data
pagg_data_val_bAccount.exceptAll(payment_data_val_bAccount).show(10, False)

# Commit job
job.commit()
spark.stop()