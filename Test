from pyspark.sql import SparkSession
from pyspark.sql.functions import col, udf
from pyspark.sql import DataFrame
import boto3

# Initialize SparkSession
spark = SparkSession.builder.appName("CleanseCaseClass").getOrCreate()

# ==============================
# Configuration Parameters
# ==============================

# Define paths for local testing or S3 if accessible
s3ConfigPath = "path/to/local/paths_config.txt"  # Update with your actual local path or S3 path
s3ColumnsConfigPath = "path/to/local/columns_config.txt"  # Update with your actual local path or S3 path
outputSummaryPath = "path/to/local/output_summary.txt"  # Update with your actual local path

# ==============================
# Load Configurations
# ==============================

# Helper function to read configurations
def read_config(path):
    config = {}
    with open(path, 'r') as f:
        for line in f:
            key, value = line.strip().split('=')
            config[key.strip()] = value.strip()
    return config

configMap = read_config(s3ConfigPath)
inputSourcePath = configMap["inputSourcePath"]
inputTargetPath = configMap["inputTargetPath"]
outputBasePath = configMap["outputBasePath"]

columnConfig = read_config(s3ColumnsConfigPath)

# ==============================
# Load Data from Paths
# ==============================
transactionSource = spark.read.parquet(inputSourcePath)
caseClass = spark.read.parquet(inputTargetPath)

# Initialize validation summary string
validationSummary = "Validation Results Summary:\n"

# ==============================
# Country Code Mapping UDF
# ==============================
countryCodeMapping = {
    "US": "USA", "CA": "CAN", "MX": "MEX", "GB": "GBR", "FR": "FRA",
    "DE": "DEU", "IN": "IND", "CN": "CHN", "JP": "JPN", "AU": "AUS"
}

def map_country_code(code):
    return countryCodeMapping.get(code, code)

# Register the UDF in Spark
mapCountryCodeUDF = udf(map_country_code)

# ==============================
# Null Value Validation
# ==============================
nullColumns = columnConfig.get("null_validation.columns", "").split(',')
existingNullColumns = [col for col in nullColumns if col in caseClass.columns]

nullValidationCount = caseClass.filter(lambda row: any(row[col] is None for col in existingNullColumns)).count()
validationSummary += f"Null Validation: {nullValidationCount} found\n"

# ==============================
# Direct Column Validation
# ==============================
sourceDirectColumns = columnConfig.get("direct_column_validation.columns_source", "").split(',')
targetDirectColumns = columnConfig.get("direct_column_validation.columns_target", "").split(',')

directSourceData = transactionSource.select([col(c) for c in sourceDirectColumns])
directTargetData = caseClass.select([col(c) for c in targetDirectColumns])

# Source-to-target and target-to-source differences
directSourceToTargetDiff = directSourceData.exceptAll(directTargetData)
directTargetToSourceDiff = directTargetData.exceptAll(directSourceData)

# Collect counts and IDs
directSourceToTargetCount = directSourceToTargetDiff.count()
directTargetToSourceCount = directTargetToSourceDiff.count()
directSourceToTargetIds = ", ".join(directSourceToTargetDiff.select("TRANSACTION_ID").rdd.flatMap(lambda x: x).collect())
directTargetToSourceIds = ", ".join(directTargetToSourceDiff.select("transactionId").rdd.flatMap(lambda x: x).collect())

validationSummary += f"Direct Column Validation: {directSourceToTargetCount + directTargetToSourceCount} found\n"
validationSummary += f"Source to Target Transaction IDs: {directSourceToTargetIds}\n"
validationSummary += f"Target to Source Transaction IDs: {directTargetToSourceIds}\n"

# ==============================
# Country ISO3 Validation with Mapping
# ==============================
sourceCountryColumn = columnConfig["transaction_country_iso3_validation.source_column"]
targetCountryColumn = columnConfig["transaction_country_iso3_validation.target_column"]

# Apply country code mapping to source data
sourceCountryData = transactionSource.withColumn("isoCountryCodeMapped", mapCountryCodeUDF(col(sourceCountryColumn)))
targetCountryData = caseClass.select(col("transactionId"), col(targetCountryColumn).alias("isoCountryCode"))

countrySourceToTargetDiff = sourceCountryData.select("TRANSACTION_ID", "isoCountryCodeMapped").exceptAll(targetCountryData)
countryTargetToSourceDiff = targetCountryData.exceptAll(sourceCountryData.select("TRANSACTION_ID", "isoCountryCodeMapped"))

# Count and collect IDs for differences
countrySourceToTargetCount = countrySourceToTargetDiff.count()
countryTargetToSourceCount = countryTargetToSourceDiff.count()
countrySourceToTargetIds = ", ".join(countrySourceToTargetDiff.select("TRANSACTION_ID").rdd.flatMap(lambda x: x).collect())
countryTargetToSourceIds = ", ".join(countryTargetToSourceDiff.select("transactionId").rdd.flatMap(lambda x: x).collect())

validationSummary += f"Country ISO3 Validation: {countrySourceToTargetCount + countryTargetToSourceCount} found\n"
validationSummary += f"Source to Target Transaction IDs: {countrySourceToTargetIds}\n"
validationSummary += f"Target to Source Transaction IDs: {countryTargetToSourceIds}\n"

# ==============================
# Write Validation Summary to Local Output
# ==============================
with open(outputSummaryPath, 'w') as f:
    f.write(validationSummary)

# Stop Spark session
spark.stop()