import com.amazonaws.services.glue.GlueContext
import com.amazonaws.services.glue.util.Job
import org.apache.spark.SparkContext
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.DataFrame
import com.amazonaws.services.glue.util.GlueArgParser
import org.apache.spark.sql.functions._
import org.apache.log4j.Logger

object CleanseCaseClass {

  def main(sysArgs: Array[String]): Unit = {
    // Initialize Glue and Spark context
    val spark: SparkContext = new SparkContext()
    val glueContext: GlueContext = new GlueContext(spark)
    val sparkSession: SparkSession = glueContext.getSparkSession
    import sparkSession.implicits._

    // Logger setup
    val logger: Logger = Logger.getLogger("CleanseCaseClassLogger")

    // Get the S3 config path from Glue job parameters
    val args = GlueArgParser.getResolvedOptions(sysArgs, Seq("s3ConfigPath").toArray)
    val s3ConfigPath = args("s3ConfigPath")

    // Read the configuration file from S3
    val configDF = sparkSession.read.text(s3ConfigPath)

    // Convert the config DataFrame into a Map of key-value pairs
    val configMap = configDF.collect().map { row =>
      val split = row.getString(0).split("=")
      (split(0), split(1))
    }.toMap

    // Extract input and output paths from the config file
    val inputSourcePath = configMap("inputSourcePath")
    val inputTargetPath = configMap("inputTargetPath")
    val outputCombinedExceptPath = configMap("outputCombinedExceptPath")

    // =======================
    // PART 1: Read Source and Target Data
    // =======================

    // Step 1: Read the transaction source Parquet file from the inputSourcePath in the config file
    val transactionSource: DataFrame = sparkSession.read.parquet(inputSourcePath)
      .filter($"transaction_date" > "2023-01-01" && $"transaction_date" < "2023-01-31")

    // Step 2: Read the case class DataFrame from the inputTargetPath in the config file
    val caseClass: DataFrame = sparkSession.read.parquet(inputTargetPath)

    // =======================
    // PART 2: Combine Narrative and Null Value Columns for Validation
    // =======================

    // Define all columns to compare (including narrative and other columns for null value validation)
    val expectedColumns = Seq(
      "TRANSACTION_ID", "NARRATIVE", // Narrative columns
      "aBic", "aIban", "aBank", "aBankCountry", "aBankCountryIso3", "aAddress", "aParsedAddress", "aName",
      "bBranchUniqueId", "bBic", "bIban", "bBank", "bBankCountry", "bBankCountryIso3", "bAddress", "bParsedAddress", "bName",
      "aCounterpartyBankBic", "aCounterpartyBankName", "aCounterpartyBankCountry", "aCounterpartyBankCountryIso3",
      "bCounterpartyBankBic", "bCounterpartyBankName", "bCounterpartyBankCountry", "bCounterpartyBankCountryIso3",
      "interBankBic", "interBankName", "interBankCountry", "interBankCountryIso3",
      "reference", "additionalReference", "format", "crossborder", "charges", "sanctionsStatus", "paymentsStatus",
      "aAccountNumber", "amountUsd", "aAccountOpenDate", "bAccountOpenDate", "aggregatedTransactionDirectionATeB"
    )

    // Get the list of columns in the caseClass DataFrame
    val existingColumns = caseClass.columns.toSet

    // Find which columns are missing in target
    val missingColumns = expectedColumns.filterNot(existingColumns.contains)

    // Log missing columns
    if (missingColumns.nonEmpty) {
      logger.warn(s"Missing columns: ${missingColumns.mkString(", ")}")
    }

    // Filter out missing columns and select only existing columns for comparison
    val validColumns = expectedColumns.filter(existingColumns.contains)

    // =======================
    // PART 3: Perform Source-to-Target and Target-to-Source Validation for All Columns
    // =======================

    // Select valid columns from both source and target
    val sourceData = transactionSource.select(validColumns.map(col): _*)
    val targetData = caseClass.select(validColumns.map(col): _*)

    // Perform source-to-target validation using exceptAll
    val source_to_target_diff = sourceData.exceptAll(targetData)

    // Perform target-to-source validation using exceptAll
    val target_to_source_diff = targetData.exceptAll(sourceData)

    // =======================
    // PART 4: Combine the Results and Write to S3
    // =======================

    // Combine the differences from both source-to-target and target-to-source
    val combined_results = source_to_target_diff.union(target_to_source_diff)

    // Write the combined results to S3 as a Parquet file
    combined_results.write.mode("overwrite").parquet(outputCombinedExceptPath)

    // Commit the Glue job to mark it as successfully completed
    Job.commit()
  }
}